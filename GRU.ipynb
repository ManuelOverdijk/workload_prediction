{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dionatrafk/workload_prediction/blob/master/GRU.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "i_ltZriIESXy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**`GRU Gated Recurrent Unit`**"
      ]
    },
    {
      "metadata": {
        "id": "AlKmqebTD7Jx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Import dataset from git**"
      ]
    },
    {
      "metadata": {
        "id": "oHXt17riAggr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/dionatrafk/workload_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l7RofqF0AYeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.models import Sequential, load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math, time\n",
        "import os, sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CPuBj5tEAcSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, lookback=1):\n",
        "    dataX, dataY = [], [] # create 2 empty list\n",
        "    for i in range(len(dataset)-lookback-1):\n",
        "      a = dataset[i:(i+lookback),0]\n",
        "      dataX.append(a)\n",
        "      dataY.append(dataset[i+lookback,0]) # get the next value\n",
        "    return np.array(dataX), np.array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2PwKahmA3T_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'workload_prediction/trace60.csv' \n",
        "\n",
        "# Dataset configuration\n",
        "dataset = pd.read_csv(filename, usecols = [1], header=None)\n",
        "dataset.columns = [\"request\"]\n",
        "dataset = dataset.values #convert to the array\n",
        "dataset = dataset.astype('float32') # convert to float\n",
        "\n",
        "# length of our dataset\n",
        "training_size = int(len(dataset)*0.67)\n",
        "testing_size = len(dataset)-training_size\n",
        "\n",
        "# split the data set\n",
        "train, test = dataset[0:training_size:], dataset[training_size:len(dataset),:]\n",
        "\n",
        "# one time step to the future\n",
        "lookback = 1\n",
        "trainX, trainY = create_dataset(train, lookback)\n",
        "testX, testY = create_dataset(test, lookback)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eu710C632l58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Scaling dataset\n",
        "x_train, y_train = trainX, trainY \n",
        "x_test, y_test = testX, testY\n",
        "\n",
        "# scaling values for model\n",
        "scaleX = MinMaxScaler()\n",
        "scaleY = MinMaxScaler()\n",
        "\n",
        "trainX = scaleX.fit_transform(x_train)\n",
        "trainX = trainX.reshape((-1,1,1))\n",
        "\n",
        "trainY = scaleY.fit_transform(y_train.reshape(-1,1))\n",
        "\n",
        "testX  = scaleX.fit_transform(x_test)\n",
        "testX = testX.reshape((-1,1,1))\n",
        "\n",
        "testY  = scaleY.fit_transform(y_test.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnEO1GbiBP3s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# creating model using Keras\n",
        "model_name = 'requests_GRU'\n",
        "model = Sequential()\n",
        "model.add(GRU(units=32,\n",
        "              return_sequences=True,\n",
        "              input_shape=(1, 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(units=16))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xVG0dmsLBXlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compilation and training\n",
        "start = time.time()\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "print \"Compilation Time : \", time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "BATCH_SIZE = 140\n",
        "NB_EPOCHS = 150\n",
        "\n",
        "model.fit(trainX,trainY,batch_size=BATCH_SIZE, epochs=NB_EPOCHS, validation_split=0.1, verbose=0)\n",
        "\n",
        "print \"Training time : \", time.time() - start\n",
        "model.save(\"{}.h5\".format(model_name))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RuxALVCeq_tF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Making predictions\n",
        "\n",
        "yhat = model.predict(trainX)\n",
        "yhat = scaleY.inverse_transform(yhat)\n",
        "y_test = scaleY.inverse_transform(trainY)\n",
        "\n",
        "print 'Train samples: %d' %(training_size)+'\\n'+'Test samples: %d' %(testing_size)+'\\n'\n",
        "\n",
        "score = mean_squared_error(y_test, yhat)\n",
        "print ('Trainscore: %.2f MSE (%.2f RMSE)' %(score, math.sqrt(score)))\n",
        "\n",
        "yhat = model.predict(testX)\n",
        "yhat = scaleY.inverse_transform(yhat)\n",
        "y_test = scaleY.inverse_transform(testY)\n",
        "\n",
        "\n",
        "score = mean_squared_error(y_test, yhat)\n",
        "print ('Testscore: %.2f MSE (%.2f RMSE)' %(score, math.sqrt(score)))\n",
        "print ('%.2f' %(math.sqrt(score)))\n",
        "\n",
        "#print samples\n",
        "print'Current  Predicted'\n",
        "for i in range(0, 10):\n",
        "    print  y_test[i], yhat[i+1]\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Ok7G88iB9OT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(yhat[-100:], label='Predicted')\n",
        "plt.plot(y_test[-100:], label='Current')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.ylabel('Requests')\n",
        "plt.xlabel('Time')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}